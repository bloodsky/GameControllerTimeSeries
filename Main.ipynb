{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2f5126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-15 11:17:07.553189: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-15 11:17:07.553227: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense, Conv1D, MaxPooling1D, Flatten, Conv2D, LeakyReLU\n",
    "\n",
    "dfX = pd.read_csv('train_gesture_x.csv',header=None)\n",
    "dfY = pd.read_csv('train_gesture_y.csv',header=None)\n",
    "dfZ = pd.read_csv('train_gesture_z.csv',header=None)\n",
    "dfLabels = pd.read_csv('train_label.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06ba0fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 3D tensor\n",
    "train_gesture = np.dstack((dfX, dfY, dfZ))\n",
    "train_labels = dfLabels.values\n",
    "\n",
    "# Split training / test --> 80/20\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_gesture, train_labels, test_size=.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d2b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(trainX, testX, scale_type):\n",
    "    if scale_type == \"STANDARD\":\n",
    "\n",
    "        scalers = {}\n",
    "        for i in range(trainX.shape[1]):\n",
    "            scalers[i] = StandardScaler()\n",
    "            trainX[:, i, :] = scalers[i].fit_transform(trainX[:, i, :])\n",
    "\n",
    "        if testX is not None:\n",
    "            for i in range(testX.shape[1]):\n",
    "                testX[:, i, :] = scalers[i].transform(testX[:, i, :])\n",
    "\n",
    "\n",
    "    if scale_type == \"MINMAX\":\n",
    "\n",
    "        scalers = {}\n",
    "        for i in range(trainX.shape[1]):\n",
    "            scalers[i] = MinMaxScaler(feature_range=(-1, 1))\n",
    "            trainX[:, i, :] = scalers[i].fit_transform(trainX[:, i, :])\n",
    "\n",
    "        if testX is not None:\n",
    "            for i in range(testX.shape[1]):\n",
    "                testX[:, i, :] = scalers[i].transform(testX[:, i, :])\n",
    "\n",
    "    if scale_type == \"MAX_ABS\":\n",
    "\n",
    "        scalers = {}\n",
    "        for i in range(trainX.shape[1]):\n",
    "            scalers[i] = MaxAbsScaler()\n",
    "            trainX[:, i, :] = scalers[i].fit_transform(trainX[:, i, :])\n",
    "\n",
    "        if testX is not None:\n",
    "            for i in range(testX.shape[1]):\n",
    "                testX[:, i, :] = scalers[i].transform(testX[:, i, :])\n",
    "\n",
    "    if scale_type == \"ROBUST\":\n",
    "\n",
    "        scalers = {}\n",
    "        for i in range(trainX.shape[1]):\n",
    "            scalers[i] = RobustScaler(quantile_range=(25, 75), with_centering=False)\n",
    "            trainX[:, i, :] = scalers[i].fit_transform(trainX[:, i, :])\n",
    "\n",
    "        if testX is not None:\n",
    "            for i in range(testX.shape[1]):\n",
    "                testX[:, i, :] = scalers[i].transform(testX[:, i, :])\n",
    "\n",
    "    return trainX, testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b70a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_type = \"ROBUST\"\n",
    "# scaling con scaler di tipo \"scale_type\"\n",
    "train_x, test_x = scale(train_x, test_x, scale_type)\n",
    "\n",
    "# one-hot encoding\n",
    "train_y = tf.keras.utils.to_categorical(train_y, 8, dtype='float64')\n",
    "test_y = tf.keras.utils.to_categorical(test_y, 8, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f7e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fit(datasetX, datasetY, testX, testY):\n",
    "\n",
    "    n_timesteps, n_features, n_outputs = datasetX.shape[1], datasetX.shape[2], datasetY.shape[1]\n",
    "\n",
    "\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=10, activation='relu', input_shape=(n_timesteps, n_features),\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(1.e-2)))\n",
    "    model.add(MaxPooling1D(pool_size=8, strides=5, padding='same'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=8, strides=5, padding='same'))\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(400, activation='relu'))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    \n",
    "    print((n_timesteps, n_features))\n",
    "    model.summary()\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1.e-3)\n",
    "    #opt2 = tf.keras.optimizers.RMSprop(lr=1e-4)\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', restore_best_weights=True, patience=50)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    history=model.fit(datasetX, datasetY, epochs=300, validation_data=(datasetX, datasetY), batch_size=64, verbose=1, callbacks=[callback])\n",
    "\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    performance = model.evaluate(datasetX, datasetY, verbose=0)\n",
    "    print(\"Validation performance\")\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce65f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 3)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 306, 64)           1984      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 58, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 12, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 8, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 400)               51600     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 808       \n",
      "=================================================================\n",
      "Total params: 135,580\n",
      "Trainable params: 135,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "63/63 [==============================] - 4s 45ms/step - loss: 1.5153 - accuracy: 0.5548 - val_loss: 0.4001 - val_accuracy: 0.8972\n",
      "Epoch 2/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.3039 - accuracy: 0.9290 - val_loss: 0.2093 - val_accuracy: 0.9523\n",
      "Epoch 3/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1871 - accuracy: 0.9605 - val_loss: 0.1729 - val_accuracy: 0.9600\n",
      "Epoch 4/300\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.1630 - accuracy: 0.9592 - val_loss: 0.1403 - val_accuracy: 0.9670\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1155 - accuracy: 0.9751 - val_loss: 0.1131 - val_accuracy: 0.9753\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0952 - accuracy: 0.9814 - val_loss: 0.0749 - val_accuracy: 0.9902\n",
      "Epoch 7/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0799 - accuracy: 0.9884 - val_loss: 0.0664 - val_accuracy: 0.9883\n",
      "Epoch 8/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0661 - accuracy: 0.9879 - val_loss: 0.0613 - val_accuracy: 0.9898\n",
      "Epoch 9/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0652 - accuracy: 0.9893 - val_loss: 0.0591 - val_accuracy: 0.9902\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0574 - accuracy: 0.9897 - val_loss: 0.1008 - val_accuracy: 0.9725\n",
      "Epoch 11/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0864 - accuracy: 0.9790 - val_loss: 0.0618 - val_accuracy: 0.9852\n",
      "Epoch 12/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0544 - accuracy: 0.9908 - val_loss: 0.0401 - val_accuracy: 0.9933\n",
      "Epoch 13/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0401 - accuracy: 0.9944 - val_loss: 0.0366 - val_accuracy: 0.9935\n",
      "Epoch 14/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0404 - accuracy: 0.9923 - val_loss: 0.0306 - val_accuracy: 0.9962\n",
      "Epoch 15/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0369 - accuracy: 0.9935 - val_loss: 0.0501 - val_accuracy: 0.9893\n",
      "Epoch 16/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0505 - accuracy: 0.9864 - val_loss: 0.0636 - val_accuracy: 0.9830\n",
      "Epoch 17/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0454 - accuracy: 0.9882 - val_loss: 0.0269 - val_accuracy: 0.9967\n",
      "Epoch 18/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0355 - accuracy: 0.9914 - val_loss: 0.0194 - val_accuracy: 0.9985\n",
      "Epoch 19/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0215 - accuracy: 0.9978 - val_loss: 0.0304 - val_accuracy: 0.9945\n",
      "Epoch 20/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0303 - accuracy: 0.9947 - val_loss: 0.0316 - val_accuracy: 0.9927\n",
      "Epoch 21/300\n",
      "63/63 [==============================] - 3s 44ms/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 0.0939 - val_accuracy: 0.9793\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0959 - accuracy: 0.9757 - val_loss: 0.0272 - val_accuracy: 0.9958\n",
      "Epoch 23/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0249 - accuracy: 0.9973 - val_loss: 0.0283 - val_accuracy: 0.9952\n",
      "Epoch 24/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0181 - accuracy: 0.9987 - val_loss: 0.0178 - val_accuracy: 0.9985\n",
      "Epoch 25/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.0182 - val_accuracy: 0.9983\n",
      "Epoch 26/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0282 - accuracy: 0.9934 - val_loss: 0.0182 - val_accuracy: 0.9970\n",
      "Epoch 27/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0213 - accuracy: 0.9958 - val_loss: 0.0147 - val_accuracy: 0.9995\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0153 - accuracy: 0.9989 - val_loss: 0.0390 - val_accuracy: 0.9905\n",
      "Epoch 29/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0269 - accuracy: 0.9948 - val_loss: 0.0277 - val_accuracy: 0.9942\n",
      "Epoch 30/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0463 - accuracy: 0.9885 - val_loss: 0.0303 - val_accuracy: 0.9927\n",
      "Epoch 31/300\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0400 - accuracy: 0.9894 - val_loss: 0.0143 - val_accuracy: 0.9998\n",
      "Epoch 32/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0160 - accuracy: 0.9989 - val_loss: 0.0227 - val_accuracy: 0.9960\n",
      "Epoch 33/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.0122 - val_accuracy: 0.9995\n",
      "Epoch 34/300\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.0110 - val_accuracy: 0.9995\n",
      "Epoch 35/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0280 - accuracy: 0.9952 - val_loss: 0.0194 - val_accuracy: 0.9965\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0237 - accuracy: 0.9950 - val_loss: 0.0409 - val_accuracy: 0.9890\n",
      "Epoch 37/300\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0450 - accuracy: 0.9906 - val_loss: 0.1601 - val_accuracy: 0.9665\n",
      "Epoch 38/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1039 - accuracy: 0.9773 - val_loss: 0.0221 - val_accuracy: 0.9965\n",
      "Epoch 39/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0203 - accuracy: 0.9967 - val_loss: 0.0213 - val_accuracy: 0.9967\n",
      "Epoch 40/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0229 - accuracy: 0.9957 - val_loss: 0.0317 - val_accuracy: 0.9940\n",
      "Epoch 41/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0349 - accuracy: 0.9936 - val_loss: 0.0253 - val_accuracy: 0.9952\n",
      "Epoch 42/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0152 - accuracy: 0.9982 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0112 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.0824 - val_accuracy: 0.9765\n",
      "Epoch 58/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0915 - accuracy: 0.9772 - val_loss: 0.0630 - val_accuracy: 0.9837\n",
      "Epoch 59/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0529 - accuracy: 0.9850 - val_loss: 0.0369 - val_accuracy: 0.9918\n",
      "Epoch 60/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0382 - accuracy: 0.9908 - val_loss: 0.0184 - val_accuracy: 0.9970\n",
      "Epoch 61/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 0.0188 - val_accuracy: 0.9970\n",
      "Epoch 62/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0482 - accuracy: 0.9889 - val_loss: 0.0223 - val_accuracy: 0.9962\n",
      "Epoch 63/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0271 - accuracy: 0.9967 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0128 - accuracy: 0.9992 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.2486 - val_accuracy: 0.9607\n",
      "Epoch 89/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.2698 - accuracy: 0.9487 - val_loss: 0.0434 - val_accuracy: 0.9927\n",
      "Epoch 90/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0413 - accuracy: 0.9901 - val_loss: 0.0199 - val_accuracy: 0.9975\n",
      "Epoch 91/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0256 - accuracy: 0.9950 - val_loss: 0.0190 - val_accuracy: 0.9980\n",
      "Epoch 92/300\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0302 - accuracy: 0.9957 - val_loss: 0.0241 - val_accuracy: 0.9942\n",
      "Epoch 93/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0209 - accuracy: 0.9956 - val_loss: 0.0228 - val_accuracy: 0.9960\n",
      "Epoch 94/300\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0231 - accuracy: 0.9965 - val_loss: 0.0096 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0ZklEQVR4nO3dd3yV9fn/8dd1VnYgkLASFFBQpoCIg7pHceEWrLbVWrHW1aGt2m1ra8fP2jpxjyqKuGjF8VUBRQVZgkzZEmYSkpCdM67fH/edcBJWQE5O4L6ej0ceOee+73POlTsneZ/P53Pfn1tUFWOMMd7lS3YBxhhjksuCwBhjPM6CwBhjPM6CwBhjPM6CwBhjPM6CwBhjPM6CwJgWEpFnRORPLdx2jYic8U2fx5jWYEFgjDEeZ0FgjDEeZ0FgDipul8ztIrJARKpE5EkR6Swib4tIhYi8LyI5cduPEpFFIlImIlNFpG/cuiEiMtd93MtAarPXOk9EvnAf+6mIDNrHmq8TkRUislVEJolIN3e5iMg/RWSLiGwTkS9FZIC77hwRWezWtl5EbtunHWYMFgTm4HQJcCbQBzgfeBu4C8jDec/fAiAifYDxwE/cdZOB/4pISERCwBvA80AH4BX3eXEfOwR4Crge6AiMAyaJSMreFCoipwF/AS4HugJrgZfc1WcBJ7k/Rzt3mxJ33ZPA9aqaBQwAPtyb1zUmngWBORg9oKqbVXU98DEwU1XnqWot8DowxN1uNPCWqv6fqoaBfwBpwAnAcUAQuF9Vw6o6EZgV9xpjgXGqOlNVo6r6LFDnPm5vXAk8papzVbUOuBM4XkR6AGEgCzgSEFVdoqob3ceFgX4ikq2qpao6dy9f15hGFgTmYLQ57nbNTu5nure74XwCB0BVY8A6IN9dt16bzsq4Nu72ocDP3W6hMhEpA7q7j9sbzWuoxPnUn6+qHwIPAg8BW0TkMRHJdje9BDgHWCsi00Tk+L18XWMaWRAYL9uA8w8dcPrkcf6Zrwc2AvnusgaHxN1eB9yjqu3jvtJVdfw3rCEDp6tpPYCq/ltVjwb64XQR3e4un6WqFwCdcLqwJuzl6xrTyILAeNkE4FwROV1EgsDPcbp3PgU+AyLALSISFJGLgeFxj30c+JGIHOsO6maIyLkikrWXNYwHrhGRwe74wp9xurLWiMgx7vMHgSqgFoi5YxhXikg7t0trGxD7BvvBeJwFgfEsVV0GXAU8ABTjDCyfr6r1qloPXAxcDWzFGU94Le6xs4HrcLpuSoEV7rZ7W8P7wG+AV3FaIYcBY9zV2TiBU4rTfVQC/N1d911gjYhsA36EM9ZgzD4RuzCNMcZ4m7UIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4wLJLmBv5ebmao8ePZJdhjHGHFDmzJlTrKp5O1t3wAVBjx49mD17drLLMMaYA4qIrN3VOusaMsYYj7MgMMYYj0tYEIjIU+486gt3sV5E5N/uPOwLRGRoomoxxhiza4kcI3gG5/T753ax/mygt/t1LPCI+32vhcNhCgsLqa2t3ZeHm2ZSU1MpKCggGAwmuxRjTCtIWBCo6kfunOq7cgHwnDvN7wwRaS8iXePmW2+xwsJCsrKy6NGjB00nizR7S1UpKSmhsLCQnj17JrscY0wrSOYYQT7OVL4NCt1lOxCRsSIyW0RmFxUV7bC+traWjh07WgjsByJCx44drXVljIccEIPFqvqYqg5T1WF5eTs9DNZCYD+yfWmMtyQzCNbjXASkQYG7LCGq6iJsKq8lZrOtGmNME8kMgknA99yjh44DyvdlfKClqusjbKmoJRE5UFZWxsMPP7zXjzvnnHMoKyvb/wUZY8xeSOTho+NxrvJ0hIgUisi1IvIjEfmRu8lkYBXOBT0eB36cqFrcegBnMHR/21UQRCKR3T5u8uTJtG/ffr/XY4wxeyORRw1dsYf1CtyYqNdvrqHXOxEdQ3fccQcrV65k8ODBBINBUlNTycnJYenSpXz11VdceOGFrFu3jtraWm699VbGjh0LbJ8uo7KykrPPPptvfetbfPrpp+Tn5/Pmm2+SlpaWgGqNMaapA26uoT35w38XsXjDth2WR2JKXThKeijA3o6F9uuWze/O77/L9ffeey8LFy7kiy++YOrUqZx77rksXLiw8fDLp556ig4dOlBTU8MxxxzDJZdcQseOHZs8x/Llyxk/fjyPP/44l19+Oa+++ipXXXXV3hVqjDH74KALgj1TtrcPEmP48OFNjsH/97//zeuvvw7AunXrWL58+Q5B0LNnTwYPHgzA0UcfzZo1axJaozHGNDjogmBXn9zLquv5ems1fTpnkRr0J7SGjIyMxttTp07l/fff57PPPiM9PZ1TTjllp8fop6SkNN72+/3U1NQktEZjjGlwQJxHsD8kcrA4KyuLioqKna4rLy8nJyeH9PR0li5dyowZM/b76xtjzDdx0LUIdiWRg8UdO3ZkxIgRDBgwgLS0NDp37ty4buTIkTz66KP07duXI444guOOOy4BFRhjzL6TRHxCTqRhw4Zp8wvTLFmyhL59++72cRW1YVYXV3FYXiYZKZ7Jv33Wkn1qjDlwiMgcVR22s3XWNWSMMR7nnSBwv1sMGGNMU94JAjcJrEFgjDFNeSgIrGvIGGN2xjtB4H63GDDGmKY8EwQ+NwlilgTGGNOEZ4JA3DaBtoE2QWZmJgAbNmzg0ksv3ek2p5xyCs0Pk23u/vvvp7q6uvG+TWttjNkX3gmCNjhY3K1bNyZOnLjPj28eBDattTFmX1gQ7Ad33HEHDz30UOP93//+9/zpT3/i9NNPZ+jQoQwcOJA333xzh8etWbOGAQMGAFBTU8OYMWPo27cvF110UZO5hm644QaGDRtG//79+d3vfgc4E9lt2LCBU089lVNPPRVwprUuLi4G4L777mPAgAEMGDCA+++/v/H1+vbty3XXXUf//v0566yzbE4jY8xBOMXE23fApi93WOxD6VUXJRTwgX8v86/LQDj73l2uHj16ND/5yU+48Ubn8goTJkzg3Xff5ZZbbiE7O5vi4mKOO+44Ro0atcvrAT/yyCOkp6ezZMkSFixYwNChQxvX3XPPPXTo0IFoNMrpp5/OggULuOWWW7jvvvuYMmUKubm5TZ5rzpw5PP3008ycORNV5dhjj+Xkk08mJyfHprs2xuzAMy2CRBoyZAhbtmxhw4YNzJ8/n5ycHLp06cJdd93FoEGDOOOMM1i/fj2bN2/e5XN89NFHjf+QBw0axKBBgxrXTZgwgaFDhzJkyBAWLVrE4sWLd1vP9OnTueiii8jIyCAzM5OLL76Yjz/+GLDpro0xOzr4WgS7+uSuyqr15XTKSqVLu9T9/rKXXXYZEydOZNOmTYwePZoXXniBoqIi5syZQzAYpEePHjudfnpPVq9ezT/+8Q9mzZpFTk4OV1999T49TwOb7toY05xnWgQigogk7Kih0aNH89JLLzFx4kQuu+wyysvL6dSpE8FgkClTprB27drdPv6kk07ixRdfBGDhwoUsWLAAgG3btpGRkUG7du3YvHkzb7/9duNjdjX99Yknnsgbb7xBdXU1VVVVvP7665x44on78ac1xhxMDr4WwW74SNxRQ/3796eiooL8/Hy6du3KlVdeyfnnn8/AgQMZNmwYRx555G4ff8MNN3DNNdfQt29f+vbty9FHHw3AUUcdxZAhQzjyyCPp3r07I0aMaHzM2LFjGTlyJN26dWPKlCmNy4cOHcrVV1/N8OHDAfjhD3/IkCFDrBvIGLNTnpmGGmDxhnLapYfIb28Xhd8Tm4bamIOLTUPtEhGba8gYY5rxVhDQtk4oM8aYtuCgCYKWfNJ3WgStUMwBzlpNxnjLQREEqamplJSU7PEfmEjbmGuoLVNVSkpKSE3d/4fYGmPapoPiqKGCggIKCwspKira7XZbttXi9wnVW1J2u53XpaamUlBQkOwyjDGt5KAIgmAwSM+ePfe43R0PfUK7tCDP/WBw4osyxpgDxEHRNdRSIb8QicaSXYYxxrQpngqCoN9H2ILAGGOa8FwQ1EdtsNgYY+J5LgjCEWsRGGNMvIQGgYiMFJFlIrJCRO7YyfpDRGSKiMwTkQUick4i6wkFxLqGjDGmmYQFgYj4gYeAs4F+wBUi0q/ZZr8GJqjqEGAM8HCi6gEbIzDGmJ1JZItgOLBCVVepaj3wEnBBs20UyHZvtwM2JLAeNwhsjMAYY+IlMgjygXVx9wvdZfF+D1wlIoXAZODmnT2RiIwVkdkiMntPJ43tjjNYbC0CY4yJl+zB4iuAZ1S1ADgHeF5EdqhJVR9T1WGqOiwvL2+fXyzotzECY4xpLpFBsB7oHne/wF0W71pgAoCqfgakArkkSNDvI2JdQ8YY00Qig2AW0FtEeopICGcweFKzbb4GTgcQkb44QbDvfT97YF1Dxhizo4QFgapGgJuAd4ElOEcHLRKRu0VklLvZz4HrRGQ+MB64WhM4B3LI7RqyaZaNMWa7hE46p6qTcQaB45f9Nu72YmBE88clStDvQxWiMSXgl9Z6WWOMadOSPVjcqoIB58e1Q0iNMWY7bwWB3/lxbZzAGGO281QQhNzuIDuE1BhjtvNUEDS0CCwIjDFmO28GQcTGCIwxpoGngqDhSCEbIzDGmO08FQQht0UQiVkQGGNMA08FgXUNGWPMjrwVBAE7fNQYY5rzVhDY4aPGGLMDTwVByA4fNcaYHXgqCOw8AmOM2ZEng6DeBouNMaaRp4IgFLAxAmOMac5TQRDwWdeQMcY056kgaDh81C5XaYwx23krCGyKCWOM2YGngsAOHzXGmB15Kgjs8FFjjNmRR4PAxgiMMaaBx4LAHSOIWIvAGGMaeCoIRISgX6xryBhj4ngqCMDpHrIgMMaY7TwaBDZGYIwxDTwYBNY1ZIwx8TwYBNY1ZIwx8TwaBNY1ZIwxDTwYBGJTTBhjTBwPBoGPsJ1HYIwxjTwXBKGAjREYY0w8zwWBjREYY0xTCQ0CERkpIstEZIWI3LGLbS4XkcUiskhEXkxkPWBjBMYY01wgUU8sIn7gIeBMoBCYJSKTVHVx3Da9gTuBEapaKiKdElVPg6DfR2VdJNEvY4wxB4xEtgiGAytUdZWq1gMvARc02+Y64CFVLQVQ1S0JrAdwrklgYwTGGLNdIoMgH1gXd7/QXRavD9BHRD4RkRkiMnJnTyQiY0VktojMLioq+kZFBfxil6o0xpg4yR4sDgC9gVOAK4DHRaR9841U9TFVHaaqw/Ly8r7RCwb9PhsjMMaYOIkMgvVA97j7Be6yeIXAJFUNq+pq4CucYEgY6xoyxpimEhkEs4DeItJTRELAGGBSs23ewGkNICK5OF1FqxJYk3tCmXUNGWNMg4QFgapGgJuAd4ElwARVXSQid4vIKHezd4ESEVkMTAFuV9WSRNUEEAzY7KPGGBMvYYePAqjqZGBys2W/jbutwM/cr1ZhYwTGGNNUsgeLW52NERhjTFOeCwKbYsIYY5ryZBBEY0osZmFgjDHgxSAICADhmHUPGWMMeDEIfM6PbN1Dxhjj8F4Q+N0WgV2cxhhjAC8GQaChRWBBYIwx4MUg8Ds/sp1LYIwxDs8FQchvYwTGGBPPc0EQ9FvXkDHGxGtREIjIrSKSLY4nRWSuiJyV6OISoWGwuN4Gi40xBmh5i+AHqroNOAvIAb4L3JuwqhLIBouNMaaplgaBuN/PAZ5X1UVxyw4oNkZgjDFNtTQI5ojIezhB8K6IZAEH5EfqhjGCiLUIjDEGaPk01NcCg4FVqlotIh2AaxJWVQIFGsYILAiMMQZoeYvgeGCZqpaJyFXAr4HyxJWVONY1ZIwxTbU0CB4BqkXkKODnwErguYRVlUB2+KgxxjTV0iCIuFcTuwB4UFUfArISV1biNM41ZEFgjDFAy8cIKkTkTpzDRk8UER8QTFxZidM4xYSdR2CMMUDLWwSjgTqc8wk2AQXA3xNWVQKFAjZGYIwx8VoUBO4//xeAdiJyHlCrqjZGYIwxB4GWTjFxOfA5cBlwOTBTRC5NZGGJYmMExhjTVEvHCH4FHKOqWwBEJA94H5iYqMISJWiHjxpjTBMtHSPwNYSAq2QvHtumWNeQMcY01dIWwTsi8i4w3r0/GpicmJISy+8TfGJBYIwxDVoUBKp6u4hcAoxwFz2mqq8nrqzECvp9NsWEMca4WtoiQFVfBV5NYC2tJuT3EY7YGIExxsAegkBEKoCd/ccUQFU1OyFVJVgw4LOuIWOMce02CFT1gJxGYk+CfrEgMMYY1wF55M83ZWMExhiznSeDIOT32XkExhjj8mQQBP0+wjbpnDHGAAkOAhEZKSLLRGSFiNyxm+0uEREVkWGJrKdBMCBEYhYExhgDCQwCEfEDDwFnA/2AK0Sk3062ywJuBWYmqhYAohGodE6OdsYIrGvIGGMgsS2C4cAKVV2lqvXASzgXtmnuj8BfgdoE1gKf/BP+0RvCtQR91jVkjDENEhkE+cC6uPuF7rJGIjIU6K6qb+3uiURkrIjMFpHZRUVF+1ZNRp7zvbqYYMAOHzXGmAZJGyx2r3J2H841kHdLVR9T1WGqOiwvL2/fXrAhCKqKnMFiCwJjjAESGwTrge5x9wvcZQ2ygAHAVBFZAxwHTErYgHFjEBTbGIExxsRJZBDMAnqLSE8RCQFjgEkNK1W1XFVzVbWHqvYAZgCjVHV2QqrJyHW+VxW55xFYi8AYYyCBQaCqEeAm4F1gCTBBVReJyN0iMipRr7tLTVoENkZgjDENWjz76L5Q1ck0u26Bqv52F9uekshaCGWCP2X7GIEdNWSMMYCXziwWcVoFVcXO7KMxGyMwxhjwUhCAM05gYwTGGNOEx4Igz+0aEusaMsYYlweDoJiAzT5qjDGNPBYEuc6ZxT6hPhpD1cLAGGM8FgR5EKklgxoAIjZgbIwxXgsC56Sy7FgZgA0YG2MMngsC56SyzEgZAOGItQiMMcZjQeC0CDKjZQB23WJjjMFzQdDQIigFrGvIGGPAa0GQ7rQI0sNOEETsEFJjjPFYEARTISWbtPBWwLqGjDEGvBYEABm5pNY7QWBdQ8YY48UgSLcgMMaYeN4Lgow8QnUWBMYY08CDQZDbGAT1dh6BMcZ4MQjyCNZuRYhZi8AYY/BoEIhGaUeVBYExxuDJIHDOJego2yiprE9yMcYYk3weDALn7OLuoSoWbihPcjHGGJN8HgwCp0UwKCfMgkILAmOM8WAQOC2Cvtl1LNm4jYiNExhjPM57QZDWARB6plVTF4mxfEtlsisyxpik8l4Q+AOQ3oGuQScAvlxv3UPGmARY/RGs+CDZVbSI94IAICOP7GgZmSkBFloQGGMSYepf4YM/JLuKFgkku4CkyMhDqorp1y3bWgTGmMSoKYW6bcmuokU82iLIhepiBua3swFjY0xi1JZBdUmyq2gRbwZBei5UFTEwvx214RgrimzA2Bizn9WUQbga6quTXckeeTMIMvKgppQBXdIB+NLOJzDG7E/RMISrnNsHQKvAo0HgnFTWK72WjJDfBoyNMftXTdn22xYEbZR7Upmvppj+3dqxwILAGLM/1ZZtv+31IBCRkSKyTERWiMgdO1n/MxFZLCILROQDETk0kfU0coOAyi0MsAFjY8z+Vhv34bK6hJr6KIs3tN0jiBIWBCLiBx4Czgb6AVeISL9mm80DhqnqIGAi8LdE1dNEbh/wh2DZZAYWZNuAsTFm/2rWNTT+86+54KHpVNZFklbS7iSyRTAcWKGqq1S1HngJuCB+A1WdoqoNQ+ozgIIE1rNdRkcYdDnMe4GjOjotARswNsbsN826hjaU1RCOKlu21SatpN1JZBDkA+vi7he6y3blWuDtna0QkbEiMltEZhcVFe2f6o67ESI19FjzChkhP5+v3rp/ntcYY2pKne/ih6pitlY71z7ZUlGXxKJ2rU0MFovIVcAw4O87W6+qj6nqMFUdlpeXt39etHM/OOw0fJ8/xoUD8/jvgg1srbIL1Rhj9oOGFkH77lBd0vi/pciDQbAe6B53v8Bd1oSInAH8Chilqq27l46/CSo3cVPnBdSGY7wwY22rvrwx5iBVUwaBNMjqBtVbKa3ybotgFtBbRHqKSAgYA0yK30BEhgDjcEJgSwJr2bnDToO8vnRd9AQn987l2c/WUheJtnoZxpiDTG05pLV3xiOrSyjxaotAVSPATcC7wBJggqouEpG7RWSUu9nfgUzgFRH5QkQm7eLpEkMEjr8RNi/ktj6bKK6sY9IXG1q1BGPMQai2DFLbQ3pHqC72dNcQqjpZVfuo6mGqeo+77LeqOsm9fYaqdlbVwe7XqN0/YwIMuhwyOjFg1ZMc2SWLJ6evRlVbvQxjzEGkpsxpEaR3RKu3UlMfBmBLhfeOGjowBFJgxK3I6mn8ol8pSzdV8MmKtn8moDGmDWtsEeQiGiUL5yh5T7YIDhjDfgAZeZyy8UlyM1N4YvqqZFdkWmrhazCtdc5DNKbFasobWwQAHaWC3MwUC4I2LZQOI36Cb/U0ftmvlKnLilhlZxofGOY9DzMeTnYVxjRVWwap7RqDIIcK+nbNYmt1PeE2OJ2NBUEDt1VwQdlzhPw+nvvMDiU9IGxd7V4JyoLbtBGxqHNlstT2zlFDQAep4IjOWahCSWXbO1/JgqBBKB1G3Ero64+4uXcRr8xeR0VtONlVmd2JRqDcPXm9vDC5tRjToGHCubiuoRyp4IguWUDbHCewIIjntgquqRtPVX2EiXPsn0ubVr4OYu4kXhYEpq1oOKu44fBRIFcqOKxTJtA2jxyyIIgXyoCTbidz46fc0Gkxz366hljMDiVts0pXb79dvm7X2xnTmhpmHk1rD6EM6iWFrsEqOmenAtYiODAMuxY6D+Dm8FNsKill2lf7aZI7s/9tjQ8CaxGYNiK+RQBU+tvROVBFbmYIaJvTTFgQNOcPwDl/J71mI79I/x9Pf7om2RWZXSldDf4UyC6wFoFpOxpaBKntACgjizxfBSkBP+3Tg9YiOGAcegIMGs33dRJfL1/AnLWlya7I7MzW1ZBzqPNlLQLTVsQPFgMlmkWOVACQl5liYwQHlDPvxhdM4S9pL3D7hC+oDdtkdG1O6RrI6QntrEVg2pBmXUNFsUyyY85lKjtlt82TyiwIdiWrC3LKnRwfm0vHrXP5x7vLkl2RiafqtAg6uEGwbYNz/LYxyVZT5lwKN5hGNKZsDmeQEXVaCU6LwILgwDLsGkhtx287f8yTn6xm9hq7ilmbUVUE4artLYJYBCo3J7sqY7bPMyRCWXU9JZpNarQSIvV0yk6lqKKuzU1saUGwO6EMGPJdBpR/xOB2Vdz2ynxq6vfiU2c0Ai+OhqVvJa5Gr2o4YqhDT2jnXv/IxglMW9Aw8yhQWl1PKVnu8q3kZaZQF4lR0cYuYm9BsCfH/BDRGA8c/gVrSqr5/lOfU1LZwqbdivfhq3dgyp+droy2YOlkqNiU7Cq+uYZzCBpaBABlXyevHmMaNMwzhDOdxFZ1g6C6hE7ZKQBs2da2uocsCPakQ0/oM5KCVS/z4OX9mF9YxgUPfcKyTRV7fuzc55zvmxfC1zMSW2dLVGyGl66Aj/9fsiv55rauBsQ5YqghCKxFYNqC2vLGgeKtVXEtgqpi8jKdIGhrA8YWBC1x7FioLuY83wxevv546iMxLn74E95fvJs+6YpN6FfvsPSQMYQDWURmPt569e7K6o+c72s/TW4d+0PpasjOd64nkZLl/OF5OQiqbfyqzYjrGtrqjhEATVsEbewQUguCluh1KuT2gc/HMbigHZNu+ha98jK57vnZPDpt5U4HfmrnvIBolB8tP4bna0egi97gty9+yJKN25LwA7hWT3W+b1504P/jaDhiqEG77t4NguLl8Lde8PF9ANRFom1uMNJTGgaLga2V9ZTGdQ3lZbbNaSYsCFpCBIaPhQ3zYMHLdMlOYcL1x3POwK7c+/ZSfj5hfpPzDAq3VlHy0ePMjPXlhovPYuiltxGUKHnLXuJ7T32+dwPO+4sqrPoIsroB2ja6qr6J0tWQ02P7/XYFREq/9ub8UGs/ARQ++AP1X77BWf/8iJtenGdhkAyx2PYL1+O0CKIpzngB1VvJTgsQCvgsCA5YR42BTv3g9evh8dNI+3oqD44ZzM/O7MNr89Zz6j+mct4DH3PhQ5/w+wceIz+2kZxv/ZDRxxzC4MHHQK9TGZvxEVsrqvnPjCRc66B0NZR/Dcff6EzLsPaT1q9hf6mrcA4fbdIiKKCuZC2/m7SImasP8NbO3lo/x/kEWnAMvjeuJ3PrIt76ciPjPrIr7bW6+grQWJMxgqyMdOd+dTEiQl4bvFKZBUFLpWTB9R/DqAedf0L/uRgZdyK3+F/lxfMzOCq/HZ2yUslKDXBt+nSioWz6nHrl9scf80NSqjdyc/5yHpm2ksp9OXysrgLWTN+3+ldNc773PgsKhsHaT4jFlPpI27ta0h6VrnG+52wPghX17cmIVZJJNR8s8dj5BOvnQv7RRC57npJYJs+m3cd3+gb52ztL+WylXX+7VTWbZ2hrVT0dMkLOdNTVzu+iU3bbO6nMgmBv+AMw9Ltw8xw49z4IZcLUeznh/y7g0S1X8pT+nudzn+f4uun4j7ocgmnbH9tnJGQXcJ28ybaqap6evnrXr7MzpWvgybPgmXNh5ZS9r331NMjqCrm94dAR6Mb5XPrv9/jBM7P2/rmSLf4cAqCmPspzi51AO/uQKB8u3ZKsylpffRVsWQL5Q3lrdYzv195Ge6nhbn2QHh3TuXn8PLZsa1sDkwe1huklGrqGqurp2CwIrEVwsAikwDHXwrXvwm1fwfn/gsNOdc5u/epdZ5thP2j6GH8AzrqbjOL5PNB5Mo99vIry6hZeAW3tp/D4abBtPZqWs/fX6I3FYPXH0PNkEKGyy7GIxsjaMofpK4r5srB8754v2eLPIQAe+HA5CyudAblvF0RYVVzlnWtOb1wAGkW7DeWRqSuJ5vXDd9YfCKyZxovHrqO6PsLN4+d5b9wkWRomnIvrGsrJCEFGLlTFtwjaVjhbEHxTmZ3g6KvhokedYLh9Ody1ETr333HbAZfA0ddwdvlLHF0/i8c+Xrnn51/4Kjw7inCoPX/o8gAPVp0By98jumUv5j7ashiqi6HXyWyrDfODDyCsfn49oJS0oJ/nPlvT8udqC7auhrQcSGvPV5sreOyjVQweOBCAo9s7AfDBEo+0CtbPAWB69SEs3VTBj04+DN8x10K3oXSZcTf3jCxg5uqtvDx715PyqSq/fuNLxk1rwfvR7F7cRWlUlZLGFkGHuBZBKqXV4TbVLWtBkAi+3ezWkfdC54E8mDqOSR/N4qYX5zJ12RaiO/nEpms/RV+7nq8z+nN80Z2MXxliXueLqdMgHzz9B74uqW5ZPaud8YHNucfy/ac+Z+7GeqpyB9K7ZgEXDsln0vwNlFYl7oLaE2at49pnZrF1f71G6WrI6Uk4GuMXExeQmRrgxvNOAF+AnPrNHNkliw+WemScYMNcNLuA+2duI799GqMGdwOfH86/H6pLuLD4cY7r1YG/TF6yy0+h7yzcxH9mfM3f3l3Gii0tOFHS7FrczKPV9VHqI7GmYwSqjecSFLd0hoJWYEHQ2oKpcPmzZPijTMi+n67LX+Dvz7zCCfe8y0UPf8L3n/qcm16cy40Pvk7p05ezKpLLeUU/5uSj+jD1tlN58sdns/6QUZxY/X+M/tdbPDV9NZHoHj5ZrJpGZWYPznxiBcs2VfDgd4bS/siTYf0cvj+sE3WRGK/M+YbTOKvCsrehsukn8fnryvjVG1/ywdItfOfxGd+8bzQahqKvoENP7n//K75YV8Y9Fw6kY3Y6ZHeD8kJO79uJWWtKW971diBbP4eynIHMWVvKdSf2JOh3/6S7HgXH3oDMfYZ/HFdLbTjGH/+3ZIeHV9dH+OP/FtO7UybpIT/3vLXjNmYvxLUIGj745GSEnPNconWwelqbPLvYgiAZOh6GXPI4XX3b+JU+wVspd/FR7Gpur/w7Pcs+ZU3hen5Z+jvS/MqCkx7llZ+cw/+7/Ci6tEtFROh1/u2kST0/y/mEu/+3mPMemL7LmVE3lGyjduVHvFF2GId1ymTyLScyckAXOPRbEAtzZHQZw3t04PkZa3faKmmx+S/B+DHw8HGw5L8AbKsNc/P4eXTKSuXhK4eypqSKMY99xuZvMnj5wd1QsYGlHU7j4akrGT2sO+cO6uqsa3cIlBdy2pGdicaUqV8d5N1DVSVQuobpNYeQmRLgsmHdm64/9S7Izqdg2u389MQ8/jt/A1OXNd0nD364gg3ltfz54oHcfNrhTFlWxEd2edZ9V1sG4odQJiVuEHTMCMHgK6Fjb3jjx+SnOQEw/vOvCe/pQ1wrCSS7AM868lw44hxnorTCWaSsmc4Ji17nhG1TnLnMY1H47mtc1OuUHR/bqS8cdjqXbn6brCt+yh8mr+DSRz/jxN65fOuwjpwTm0r7lW9SVryJQG0xqVJDhwFn8splxxNo+MR4yLEgPlj+Hjf0/zYPTv6COTOF4cefusPL1dRHWbGlklXFlawurqJ9WpAxww8hNeh3Nti2Ad75JeQf7QyYv3wVetQVPFc8hDO2LeJH/SN02tyJ3O9dzzXPz2f0uM945prh9MjNaNGuqg1HmfTFBvpWfMLAT/9N3VFXc/WMrvTM9fO7Uf22b9iuANZ+yuDu7emYEeLDpVu4YHC+c3jlO3dALMKWwy/j7jV9WVHu47kfDKeTe0HxA9KGuQC8vKETFx+TT0ZKsz/nlEy4aBw8fxHXb/gtb+T+lF+9vpC7L+jPyX3yWLu1msc/XsXFQ/M5pkcHBhW04z8zvuZPby1m8mEnbn+vmJarKXMOHRVp7G7NyQhBKB0uHgdPnMmR8/7Itd/6KU9OX82q4ioe+s5Q8rJSklq2HGhnHw4bNkxnz56d7DISI1IHy9+Dha85h5seNXrX2654H/5zCfQ+i9rjf8bDKzsyc/5Cri//F6f5v2BFrBvrpQvtc7vQs1dvss+6y+mWijfuZNj4RZNFNUdcROr5f0cy81i0oZz/zPiaN79YT7V7NrSI0wt0aMd0fnNuP04/Mg8ZP9o5KumGT6hO70rlu38h94sH8eF+2klt5xxN0eds5h53Pz/4zwJU4eErhzLi0AznBLddjKtU1kUY+9xs1qxcxuSUOynUPMYG/0xxrY/XfnwCA/Lbbd/4gz/C9H/Cb4q47dWFTF+0lk+Pm4HMfIRoeieKoxl0qV1JtabwGqfycvuxvHDDSWSnBvf2N9U2TP0rOvUvDKh9gtd/+m36dM7a+XYLJsBr17G11yi+vfYqiqoi5GWlkJ0aYMu2Oj687RTy0v3g8/P2wk3c8MJc7rloAFcee2jr/jwHg4nXOgF9yzwmzinktlfmM+32Uzi0o/uhZ+q9MPUvcNkzvFE/nDteW0D7tBA3n344ffNCHFE7n4yqQmdMIb0jtD+k6Rn034CIzFHVYTtbZy2CtiSQAn3Pd7725LDT4fTfwqcPkPrcSH5WMBwiX6Epdcw/8k6+zB/NqCEFu/8nN+oBWDcT0nL47/IaVs79kB8vfZOyZe8zLvUHfFzemXR/lJsOb8/Rh7Sja/s0OmensnCrjzs/rueHz83m53mfc3PFezySNpZnxq1m87alwHEcLgWccYjwiytH4cvqDLOegMm3MVRjTPrROO58/gO+fnYsxwemIV0HEj33X8Q6DyTgE3w+AaCsup6rn57F+vXreLvLE2RWCZ8PvI9eWzL5yVHdmoYAOH80GoU/debPgXRqNYxvRjUTOJM/loymxpfOLwdW873g+1y18CV6la7jlqfv5tEfnrq9dXMA0fVzWCMF9O+Zv+sQABh0OZSvo8MHdzNjWCe+DA1m5vKNrN24he/1qiLvpb/Cpi8h9whGXvAgw3t24M9vLaEuHON7xx9qLYO9ETfPUEOLoENGaPv6E3/ufNj730+5cPCVnDA8xCtflpL9vyX09s0nQ2p2eMr5h/8Y/ym/4Iiu7baPAe1n1iI40NVVwrz/wOfjnHmEzv8X5B6+10+jqsxeW8rG5XMZMu83dK9evPvtgxlsyjiC7LKlrA324p/5/6R9RgqHdkzn8E6ZHN4pi165GY3/1AGY/RT876fQqT9aspxoNMYb0RM42fcF7aliXPQ8nvZdQs+uefTrls3iFWs5vWwC14XeIxCrhcuegX4X7Lqo2nKY/TTUlhGu3saUxYV8kn4Gke7Hc0SXLE7uk7f9k9n8l4i9cSOLowU83ePvfPfM4RzeKZPM5t0rbZUq9ff24s2qAaReNo7zj+q2x+1562fO7yBeMAO6DYEuA2HR61BdzLZjbuaW9WcwdUU5R3TO4jfn9ePYXh0S9k/ooPL46ZCaDd99nXvfXsqT01fx1Z/ORiTu76B4Bbx8pdMtHHaO/Ium5bKp62nMyxjBgnB3arYVE6ksZsS2tzmPj3k7egx36o3cMepoxgw/ZJ9K212LIKFBICIjgX8BfuAJVb232foU4DngaKAEGK2qa3b3nBYErSAWdc5ejtY54xW+gHNIYoNtG53j19fPdqbb+N6b0KFXy557zrPw9i9h4KXETrydiSt9lBZv4qTV99N3y/8AqJZ0SmKZ5EgFmdRA/4vhlDshr8/+/TmXv094/JVsiWbweexISjWLcGoHUjI7kJ6dQ3b7jmRkdyAlM4fUzPakZXUgLTObjNRU0lP8hPy+pn/gransa7h/IH/xXcfP7/oboUAL/kmrOjPPasxpfQZSILvAOdkRoKYU3rkT5o9HMzqxLZTH0vIgm8LpVJABqe0IZeaQkt6OlIx2pGVmk5bdgZTsPNLbdyKjfScy0lLJCPm924p44GjoMggue5pfTJzPtK+KmHnXGbvePhpx5idKyW76N+bSWIyyKf+i/cd3syWtJ8XnPk3/AUftU2lJCQIR8QNfAWcChcAs4ApVXRy3zY+BQar6IxEZA1ykqrvpGLcgOCjEYjsfE1j9sTMZXk0pWr0V9YfwHXcDdBmQuFoK51A7+S5i5YUEarcSiu753IxaDVJJGjWkUCcp1EsK9b40or4UIv5Uor5U1B8i5k8Bfwj1h1B/CuoPQSAFCaTgC4SQQAriD+DzB/EFgvj8ISQYcu77g/j8AfyBAOIL4Pf78fn9+Ou34dtWSGjdJ3Rb9QrPD3yG715y0f7dJ1+955zIWF1CrLqE6vIifHXbSIlU4Gf3R7nUaZAqUqghlTpxvsK+FMK+VKL+FKK+VKL+VGL+FDSQAoFU58OGu18kEEL8ISSYii+Q4uyXxu9B/IEQfve2zxdw9pG7z/wB534g4Mfn8+Nv3LcB/O56EcHv8+H3SWJC/G+HUdP7HN7reQf/en85oYCPd35y0jd/3pUfwivXwFl/hKHf26enSFYQHA/8XlW/7d6/E0BV/xK3zbvuNp+JSADYBOTpboqyIDAJFa51upjqKqgsL6G8rIS6qjLCVaVEqsvRukq0rgKpr4RwLRKpwRepxh+tIxCtIRirJRCrI6BhglpPkDAhwgTZ/1OPfxUrIOPWT8nv2G7PG+8PqlBfCXWV1NdUUF62lcryEuq3FRGpKCJWvZVYfTXUVyH1lUikhkCkBn+0xtknsTqCsVpCWk9Aw6RQR4gwPlq3ezqmQgznS92vKD5i8V+yfZ0A2ri9s14R1N0Gdz0IBbqBRyPn87fIGNqnB7nxlMO57qQWtpb3pKrYmapiHyVrsDgfiD9LqRA4dlfbqGpERMqBjkBx/EYiMhYYC3DIIfvWP2ZMiwRTna+szmTmHk7m/nreWAyi9cTCtdTX1xKuryVSX0ckHCYaqSccricWricaqScWqScajRCLRohFIsRiETQWJRaLEQ2kEcksIJpdQKeOOeR33M0g8f4m4szCm5JFKLsreZ0h75s+pyrEImiklnBdHeH6GiL1dXH7p45ouJ5ouI5oNEw0HCYaCaOxMBqNEIuEUY2i0UjjMo3F0FgUjUWdbs5YxPnSmPMVi4LGUBRpWKYx53ek0abLwN0WRJ34QGOIKjQ8Hm28JnkRfejYZwyThoygf7d2+H37sdXxDUJgTw6IkTFVfQx4DJwWQZLLMWbv+XzgS8UXTCU1HQ7gsxf2LxHwBxF/kFBKFqE9P6LNOzrZBeyDRI7orAfiT3UscJftdBu3a6gdzqCxMcaYVpLIIJgF9BaRniISAsYAk5ptMwn4vnv7UuDD3Y0PGGOM2f8S1jXk9vnfBLyLc/joU6q6SETuBmar6iTgSeB5EVkBbMUJC2OMMa0ooWMEqjoZmNxs2W/jbtcClyWyBmOMMbvn0bM+jDHGNLAgMMYYj7MgMMYYj7MgMMYYjzvgZh8VkSJg7T4+PJdmZy17lO0H2wcNbD94Zx8cqqo7PRn8gAuCb0JEZu9qrg0vsf1g+6CB7QfbB2BdQ8YY43kWBMYY43FeC4LHkl1AG2H7wfZBA9sPtg+8NUZgjDFmR15rERhjjGnGgsAYYzzOM0EgIiNFZJmIrBCRO5JdT2sQke4iMkVEFovIIhG51V3eQUT+T0SWu99zkl1roomIX0Tmicj/3Ps9RWSm+3542Z0q/aAmIu1FZKKILBWRJSJyvNfeCyLyU/dvYaGIjBeRVC++F5rzRBCIiB94CDgb6AdcISL9kltVq4gAP1fVfsBxwI3uz30H8IGq9gY+cO8f7G4FlsTd/yvwT1U9HCgFrk1KVa3rX8A7qnokcBTO/vDMe0FE8oFbgGGqOgBnevwxePO90IQnggAYDqxQ1VWqWg+8BFyQ5JoSTlU3qupc93YFzh9+Ps7P/qy72bPAhUkpsJWISAFwLvCEe1+A04CJ7iZe2AftgJNwrgGCqtarahkeey/gTL2f5l4RMR3YiMfeCzvjlSDIB9bF3S90l3mGiPQAhgAzgc6qutFdtQnonKy6Wsn9wC8A92rkdATKVDXi3vfC+6EnUAQ87XaRPSEiGXjovaCq64F/AF/jBEA5MAfvvRd24JUg8DQRyQReBX6iqtvi17mXBj1ojyEWkfOALao6J9m1JFkAGAo8oqpDgCqadQN54L2Qg9MC6gl0AzKAkUktqo3wShCsB7rH3S9wlx30RCSIEwIvqOpr7uLNItLVXd8V2JKs+lrBCGCUiKzB6RI8DaevvL3bPQDeeD8UAoWqOtO9PxEnGLz0XjgDWK2qRaoaBl7DeX947b2wA68EwSygt3t0QAhngGhSkmtKOLcv/ElgiareF7dqEvB99/b3gTdbu7bWoqp3qmqBqvbA+b1/qKpXAlOAS93NDup9AKCqm4B1InKEu+h0YDEeei/gdAkdJyLp7t9Gwz7w1HthZzxzZrGInIPTV+wHnlLVe5JbUeKJyLeAj4Ev2d4/fhfOOMEE4BCcKb0vV9WtSSmyFYnIKcBtqnqeiPTCaSF0AOYBV6lqXRLLSzgRGYwzYB4CVgHX4HwY9Mx7QUT+AIzGOaJuHvBDnDEBT70XmvNMEBhjjNk5r3QNGWOM2QULAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmNakYic0jADqjFthQWBMcZ4nAWBMTshIleJyOci8oWIjHOvZ1ApIv9057P/QETy3G0Hi8gMEVkgIq83zOkvIoeLyPsiMl9E5orIYe7TZ8ZdF+AF9yxXY5LGgsCYZkSkL87ZpyNUdTAQBa7EmaRstqr2B6YBv3Mf8hzwS1UdhHMWd8PyF4CHVPUo4AScGS/BmQX2JzjXxuiFM9+NMUkT2PMmxnjO6cDRwCz3w3oazmRsMeBld5v/AK+58/y3V9Vp7vJngVdEJAvIV9XXAVS1FsB9vs9VtdC9/wXQA5ie8J/KmF2wIDBmRwI8q6p3Nlko8ptm2+3r/Czx89hEsb9Dk2TWNWTMjj4ALhWRTtB4jedDcf5eGmap/A4wXVXLgVIROdFd/l1gmntFuEIRudB9jhQRSW/NH8KYlrJPIsY0o6qLReTXwHsi4gPCwI04F3MZ7q7bgjOOAM7UxY+6/+gbZvUEJxTGicjd7nNc1oo/hjEtZrOPGtNCIlKpqpnJrsOY/c26howxxuOsRWCMMR5nLQJjjPE4CwJjjPE4CwJjjPE4CwJjjPE4CwJjjPG4/w/y4YJi3hdX4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation performance\n",
      "[0.008331581950187683, 1.0]\n"
     ]
    }
   ],
   "source": [
    "my_fit(train_x, train_y, test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
